{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Cost Functions](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Cost Functions](#toc1_)    \n",
    "    - [Mean Squared Error (MSE)](#toc1_1_1_)    \n",
    "    - [Mean Absolute Error (MAE)](#toc1_1_2_)    \n",
    "    - [Cross-Entropy Loss (Log Loss)](#toc1_1_3_)    \n",
    "    - [Categorical Cross-Entropy Loss](#toc1_1_4_)    \n",
    "    - [Hinge Loss (Support Vector Machines)](#toc1_1_5_)    \n",
    "    - [Huber Loss](#toc1_1_6_)    \n",
    "    - [Binary Cross-Entropy Loss](#toc1_1_7_)    \n",
    "    - [Kullback-Leibler Divergence](#toc1_1_8_)    \n",
    "    - [Negative Log-Likelihood Loss (NLL)](#toc1_1_9_)    \n",
    "    - [Cosine Proximity Loss](#toc1_1_10_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure, here are the cost functions you mentioned, each with their own sub-sections:\n",
    "\n",
    "### <a id='toc1_1_1_'></a>[Mean Squared Error (MSE)](#toc0_)\n",
    "\n",
    "- **Definition**: This function calculates the square of the difference between the predicted and actual values and averages it over all the data points.\n",
    "- **Intuition**: The MSE cost function measures the average squared difference between an observation’s actual and predicted values. The output is a single number representing the cost, or score, associated with our current set of weights.\n",
    "- **Use Case**: It is the most common cost function used in regression problems.\n",
    "- **Formula**: $$MSE = \\frac{1}{n}\\sum_{i=1}^{n}(Y_i - \\hat{Y}_i)^2$$\n",
    "- **Limitations**: It is sensitive to outliers as it squares the residuals and thus, larger errors are noted more than smaller ones.\n",
    "- **Cautions**: Because of its sensitivity to outliers, it might not provide the best model for real-world prediction if your data has many outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <a id='toc1_1_2_'></a>[Mean Absolute Error (MAE)](#toc0_)\n",
    "\n",
    "- **Definition**: This function calculates the absolute difference between the predicted and actual values and averages it over all the data points.\n",
    "- **Intuition**: MAE measures the average magnitude of the errors in a set of predictions, without considering their direction. It’s the average over the test sample of the absolute differences between prediction and actual observation.\n",
    "- **Use Case**: It is often used in regression problems and is less sensitive to outliers than MSE.\n",
    "- **Formula**: $$MAE = \\frac{1}{n}\\sum_{i=1}^{n}|Y_i - \\hat{Y}_i|$$\n",
    "- **Limitations**: It does not punish large errors as much as MSE does. Therefore, if the consequences of large errors are particularly bad, you should not use MAE.\n",
    "- **Cautions**: Like MSE, MAE also does not indicate underperformance or overperformance of the model (whether the model is underfitting or overfitting).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <a id='toc1_1_3_'></a>[Cross-Entropy Loss (Log Loss)](#toc0_)\n",
    "\n",
    "- **Definition**: This cost function measures the performance of a classification model whose output is a probability value between 0 and 1.\n",
    "- **Intuition**: Cross-entropy loss increases as the predicted probability diverges from the actual label. So predicting a probability of .012 when the actual observation label is 1 would be bad and result in a high loss value.\n",
    "- **Use Case**: It is the most common cost function used in binary classification problems.\n",
    "- **Formula**: $$CrossEntropyLoss = -\\frac{1}{n}\\sum_{i=1}^{n}[y_i*log(\\hat{y}_i) + (1-y_i)*log(1-\\hat{y}_i)]$$\n",
    "- **Limitations**: It can be more sensitive to model misspecification and can sometimes lead to unstable models.\n",
    "- **Cautions**: It should be used when the output of your model represents the probability of a binary outcome.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <a id='toc1_1_4_'></a>[Categorical Cross-Entropy Loss](#toc0_)\n",
    "\n",
    "- **Definition**: This is an extension of the Cross-Entropy loss function for multi-class classification problems.\n",
    "- **Intuition**: It measures the dissimilarity between the predicted and actual probability distributions for the categorical classification task.\n",
    "- **Use Case**: It is used in multi-class classification problems.\n",
    "- **Formula**: $$CategoricalCrossEntropyLoss = -\\frac{1}{n}\\sum_{i=1}^{n}\\sum_{j=1}^{m}y_{ij}*log(\\hat{y}_{ij})$$\n",
    "- **Limitations**: It requires that the output of your model is a probability distribution over your classes.\n",
    "- **Cautions**: It should be used when the outputs of your model represent the probabilities of mutually exclusive outcomes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_5_'></a>[Hinge Loss (Support Vector Machines)](#toc0_)\n",
    "\n",
    "- **Definition**: This function is primarily used with Support Vector Machine (SVM) classifiers. It's used for \"maximum-margin\" classification, mainly for binary classification problems.\n",
    "- **Intuition**: Hinge loss is used for \"maximum-margin\" classification, most notably for support vector machines (SVMs). For an intended output \\(t = ±1\\) and a classifier score \\(y\\), the hinge loss of the prediction \\(y\\) is defined as \\(max(0, 1 - ty)\\).\n",
    "- **Use Case**: It is primarily used with Support Vector Machine (SVM) classifiers.\n",
    "- **Formula**: $$HingeLoss = max(0, 1 - t*y)$$\n",
    "- **Limitations**: It is not differentiable at \\(t*y = 1\\), which can complicate optimization.\n",
    "- **Cautions**: It should be used for binary classification problems where the output of the model is the class score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <a id='toc1_1_6_'></a>[Huber Loss](#toc0_)\n",
    "\n",
    "- **Definition**: This is often used in regression problems. Compared with MSE, Huber loss is less sensitive to outliers because it treats error as square only if the absolute error is less than a certain threshold (usually 1).\n",
    "- **Intuition**: Huber loss is less sensitive to outliers in data than squared error loss. It’s quadratic for small errors and linear for large errors.\n",
    "- **Use Case**: It is often used in robust regression, M-estimation and additive modelling.\n",
    "- **Formula**: $$HuberLoss = \\begin{cases} \\frac{1}{2}(y - \\hat{y})^2 & for |y - \\hat{y}| \\leq \\delta, \\\\ \\delta |y - \\hat{y}| - \\frac{1}{2}\\delta^2 & otherwise. \\end{cases}$$\n",
    "- **Limitations**: The value of \\(\\delta\\) (the threshold) can have a significant effect on the performance of the model and may need to be tuned.\n",
    "- **Cautions**: It should be used when you want to balance between Mean Absolute Error and Mean Squared Error and when your data contains outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <a id='toc1_1_7_'></a>[Binary Cross-Entropy Loss](#toc0_)\n",
    "\n",
    "- **Definition**: This is a special case of the Cross-Entropy loss function, used when our model predicts a binary output.\n",
    "- **Intuition**: It measures the performance of a classification model whose output is a probability value between 0 and 1.\n",
    "- **Use Case**: It is used when our model predicts a binary output.\n",
    "- **Formula**: $$BinaryCrossEntropyLoss = -\\frac{1}{n}\\sum_{i=1}^{n}[y_i*log(\\hat{y}_i) + (1-y_i)*log(1-\\hat{y}_i)]$$\n",
    "- **Limitations**: It can be more sensitive to model misspecification and can sometimes lead to unstable models.\n",
    "- **Cautions**: It should be used when the output of your model represents the probability of a binary outcome.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <a id='toc1_1_8_'></a>[Kullback-Leibler Divergence](#toc0_)\n",
    "\n",
    "- **Definition**: This is a measure of how one probability distribution diverges from a second, expected probability distribution.\n",
    "- **Intuition**: It is often used to measure the (dis)similarity between two probability distributions. A KL divergence of zero indicates the distributions are identical.\n",
    "- **Use Case**: It's often used in unsupervised learning, specifically in scenarios where you want to measure how one probabilistic model approximates another.\n",
    "- **Formula**: $$KLDivergence = \\sum_{i} P(i) * log(\\frac{P(i)}{Q(i)})$$\n",
    "- **Limitations**: It is not symmetric, meaning the divergence of \\(P\\) from \\(Q\\) is not the same as the divergence of \\(Q\\) from \\(P\\).\n",
    "- **Cautions**: It should be used when you want to compare two probability distributions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <a id='toc1_1_9_'></a>[Negative Log-Likelihood Loss (NLL)](#toc0_)\n",
    "\n",
    "- **Definition**: This is a common cost function for multi-class classification problems. It's similar to Cross-Entropy Loss but without the log function.\n",
    "- **Intuition**: It is the sum of the log of the likelihoods for each individual instance. The lower the NLL, the better.\n",
    "- **Use Case**: It is used in multi-class classification problems.\n",
    "- **Formula**: $$NLLLoss = -\\frac{1}{n}\\sum_{i=1}^{n}log(\\hat{y}_{i})$$\n",
    "- **Limitations**: It can be more sensitive to model misspecification and can sometimes lead to unstable models.\n",
    "- **Cautions**: It should be used when the output of your model represents the probabilities of mutually exclusive outcomes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <a id='toc1_1_10_'></a>[Cosine Proximity Loss](#toc0_)\n",
    "\n",
    "- **Definition**: This measures the cosine of the angle between the true and predicted vectors, subtracting it from 1 to provide the proper loss.\n",
    "- **Intuition**: It measures the cosine of the angle between the true and predicted vectors. A smaller angle will result in a larger cosine and thus a smaller loss.\n",
    "- **Use Case**: It's often used in semantic analysis problems and other types of problems where you care about the direction of a prediction, not just its magnitude.\n",
    "- **Formula**: $$CosineProximityLoss = 1 - \\frac{\\sum_{i=1}^{n}y_i*\\hat{y}_i}{||y||_2 * ||\\hat{y}||_2}$$\n",
    "- **Limitations**: It only considers the direction of the vectors, not their magnitudes.\n",
    "- **Cautions**: It should be used when the direction of the predictions matters more than their magnitude."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
