{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Hypothesis Tests with Formulas, Code, Assumptions](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Hypothesis Tests with Formulas, Code, Assumptions](#toc1_1_)    \n",
    "  - [**One-Sample T-Test**](#toc1_2_)    \n",
    "  - [**Two-Sample T-Test (Unpaired)**](#toc1_3_)    \n",
    "  - [**Two-Sample T-Test (Paired)**](#toc1_4_)    \n",
    "  - [**Proportion Z Test**](#toc1_5_)    \n",
    "  - [**Correlation Coefficient T-Test**](#toc1_6_)    \n",
    "  - [**Linear Regression T-Test**](#toc1_7_)    \n",
    "  - [**ANOVA**](#toc1_8_)    \n",
    "  - [**Tukey HSD Test**](#toc1_9_)    \n",
    "  - [**Chi-Squared Test**](#toc1_10_)    \n",
    "- [Two Tailed vs One Tailed Tests](#toc2_)    \n",
    "  - [**One-Tailed Hypothesis Test**](#toc2_1_)    \n",
    "  - [**Two-Tailed Hypothesis Test**](#toc2_2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[**One-Sample T-Test**](#toc0_)\n",
    "   - **Use Case:** This test is used when you want to compare the mean of a sample to a known value or a theoretical expectation.\n",
    "   - **Examples:** Testing if the average height of a certain type of plant is different from 10 cm.\n",
    "   - **Hypothesis Testing:**  \n",
    "     - $$H0: \\mu_{test} = 0$$\n",
    "     - $$H1: \\mu_{test} \\neq 0$$\n",
    "   - **Formula:**\n",
    "     - $ t = \\frac{\\overline{x} - \\mu_{test}}{\\left(s\\,\\big/ \\sqrt{n}\\right)}$\n",
    "   - **Code:**\n",
    "     ```python\n",
    "     # first argument is an array, second argument is the hypothesis value\n",
    "     one_sample_test = stats.ttest_1samp(store1, 14.5)\n",
    "     # outputs t-test statistic and a p-value\n",
    "     TtestResult(statistic=7.203710690696487, pvalue=1.1660253276676903e-10, df=99)\n",
    "     ```\n",
    "   - **Assumptions:**\n",
    "     - IID: Data points in sample are independent of each other and from the same population.\n",
    "     - Normality: The mean of the sample comes from a normal sampling distribution.\n",
    "       - Sample itself is normally distributed\n",
    "       - Sample size is large enough (n > 30)\n",
    "     - HomoThe variance of the unknown sample population, (the one we draw our mean from), is the same as our known sample population\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## <a id='toc1_3_'></a>[**Two-Sample T-Test (Unpaired)**](#toc0_)\n",
    "   - **Use Case:** This test is used when you want to compare the means of two independent groups to see if they are significantly different from each other.\n",
    "   - **Examples:** Testing if the average height of plants grown with two different types of fertilizer is different.\n",
    "   - **Hypothesis:**  \n",
    "     - $$H0: \\mu_1 -  \\mu_2 = 0$$\n",
    "     - $$H1: \\mu_1 -  \\mu_2 \\neq 0$$\n",
    "   - **Formula:**\n",
    "     - $ t = \\frac{(\\overline{X}_1 - \\overline{X}_2) - (\\mu_1 - \\mu_2)}{s_p \\sqrt{\\frac{1}{n_1}+\\frac{1}{n_2}}}$\n",
    "     - Where the $\\overline{X}_1$ and $\\overline{X}_2$ are the sample means, $(\\mu_1 - \\mu_2)$ is the population difference you want to test against and $s_p$ is the [pooled standard deviation](https://en.wikipedia.org/wiki/Pooled_variance) of the samples.\n",
    "     - $s_p = \\sqrt{\\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}}$\n",
    "   - **Code:**\n",
    "     ```python\n",
    "     # first argument is an array, second argument is the array value to compare to\n",
    "     two_sample_test = stats.ttest_ind(store_suburbs, store_downtown) \n",
    "     # outputs t-test statistic and a p-value\n",
    "     Ttest_indResult(statistic=-2.3843100564172697, pvalue=0.01805557370062323)\n",
    "     ```\n",
    "   - **Assumptions:**\n",
    "     - Data points in each group are independent of each other.\n",
    "     - The means of both samples come from a normal sampling distribution.\n",
    "       - Sample itself is normally distributed\n",
    "       - Sample size is large enough (n > 30)\n",
    "     - Data in group A are independent from data in group B.\n",
    "     - Variances of both populations are identical.\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc1_4_'></a>[**Two-Sample T-Test (Paired)**](#toc0_)\n",
    "   - **Use Case:** This test is used when you want to compare the means of the same group at two different times (for example, before and after a treatment).\n",
    "   - **Examples:** Testing the average spend of the same customers at two different stores.\n",
    "   - **Hypothesis:**  \n",
    "     - $$H0: \\mu_{test1} - \\mu_{test2} = 0$$\n",
    "     - $$H1: \\mu_{test1} - \\mu_{test2} \\neq 0$$\n",
    "   - **Formula:**\n",
    "     - $ t = \\frac{\\overline{X_D} - µ_{test}}{\\frac{s_D}{\\sqrt{n}}} $\n",
    "     - Where $X_D$ is the set of differences between paired samples, $µ_{test}$ is our mean difference that we want to compare to (0 in this case), $s_D$ is difference sample standard deviation, and n is the number of samples.\n",
    "   - **Code:**\n",
    "     ```python\n",
    "     # first argument is an array, second argument is the array value to compare to\n",
    "     stats.ttest_rel(store_suburbs, store_downtown)\n",
    "     # outputs t-test statistic and a p-value\n",
    "     TtestResult(statistic=-2.4153163510165245, pvalue=0.017556013707886925, df=99)\n",
    "     ```\n",
    "   - **Assumptions:**\n",
    "     - Data points in each group are independent of each other.\n",
    "     - Data points in group A and B are paired/matched.\n",
    "     - The mean of the samples differences comes from a normal sampling distribution.\n",
    "       - Sample itself is normally distributed\n",
    "       - Sample size is large enough (n > 30)\n",
    "     - Variances of both populations are identical.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc1_5_'></a>[**Proportion Z Test**](#toc0_)\n",
    "   - **Use Case:** This test is used when you want to compare the proportions of two groups to see if they are significantly different from each other.\n",
    "   - **Examples:** Testing if the proportion of customers who bought a product is different between two stores.\n",
    "   - **Hypothesis:**  \n",
    "     - $$H0: p_1 = p_2$$\n",
    "     - $$H1: p_1 \\neq p_2$$\n",
    "   - **Formula:**\n",
    "     - $ z = \\frac{p_1 - p_2}{\\sqrt{p(1 - p)(\\frac{1}{n_1} + \\frac{1}{n_2})}}$\n",
    "     - Where $p_1$ and $p_2$ are the sample proportions, $p$ is the pooled sample proportion, and $n_1$ and $n_2$ are the sample sizes.\n",
    "   - **Code:**\n",
    "     ```python\n",
    "     # first argument is an array, second argument is the array value to compare to\n",
    "     z_test = stats.proportions_ztest([successes_in_a, successes_in_b], [count_of_a, count_of_b]) \n",
    "     # outputs z-test statistic and a p-value\n",
    "     (statistic=-1.705800384635185, pvalue=0.08806845338765186)\n",
    "     ```\n",
    "   - **Assumptions:**\n",
    "     - IID: The samples are independent, and from the same population.\n",
    "     - Randomness: Random sampling from the population. \n",
    "     - Normality: The sample size is large enough (np > 5 and n(1-p) > 5 for both groups).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc1_6_'></a>[**Correlation Coefficient T-Test**](#toc0_)\n",
    "   - **Use Case:** This test is used when you want to determine if there is a significant correlation between two variables.\n",
    "   - **Examples:** Testing if there is a correlation between the amount of rainfall and the number of mosquitoes.\n",
    "   - **Hypothesis:**\n",
    "     - $$H_0: \\rho = 0$$\n",
    "     - $$H_1: \\rho \\neq 0$$\n",
    "   - **Formula:**\n",
    "     - $ t = \\frac{r\\sqrt{n-2}}{\\sqrt{1-r^2}}$\n",
    "     - Where $r$ is the sample correlation coefficient and $n$ is the sample size.\n",
    "   - **Code:**\n",
    "     ```python\n",
    "     # first argument is an array, second argument is the array value to compare to\n",
    "     correlation_test = stats.pearsonr(x, y) \n",
    "     # outputs correlation coefficient and a p-value\n",
    "     (correlation=0.8658002752562366, pvalue=0.011807351043126281)\n",
    "     ```\n",
    "   - **Assumptions:**\n",
    "     - The variables are continuous and numeric.\n",
    "     - The variables are linearly related.\n",
    "     - The data is homoscedastic, meaning the variance of the residuals (or \"errors\") is constant.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_9_'></a>[**Linear Regression T-Test**](#toc0_)\n",
    "   - **Use Case:** This test is used when you want to determine if the coefficients of the linear regression model are significantly different from zero. This helps to understand if a predictor variable has a significant effect on the outcome variable.\n",
    "   - **Examples:** Testing if the number of mosquitoes increases with the amount of rainfall.\n",
    "   - **Hypothesis:**\n",
    "     - $H_0: β_i = 0$ (The predictor variable has no effect on the outcome variable)\n",
    "     - $H_a: β_i ≠ 0$ (The predictor variable has a significant effect on the outcome variable)\n",
    "   - **Formula:**\n",
    "     - $ t = \\frac{β_i}{SE_{β_i}}$\n",
    "     - Where $β_i$ is the coefficient of the predictor variable in the linear regression model and $SE_{β_i}$ is the standard error of the coefficient.\n",
    "   - **Code:**\n",
    "     ```python\n",
    "    import statsmodels.api as sm\n",
    "    bp = pd.read_csv('bp.csv')\n",
    "\n",
    "\n",
    "    #seperate data into X (independant) and Y (dependant)\n",
    "    X = bp['Age']\n",
    "    y = bp['Systolic_Blood_Pressure']\n",
    "\n",
    "    # add constant\n",
    "    X_withconstant = sm.add_constant(X)\n",
    "\n",
    "    # Instantiate Model\n",
    "    myregression = sm.OLS(y, X_withconstant)\n",
    "\n",
    "    # Fit Model (this returns a seperate object with the parameters)\n",
    "    myregression_results = myregression.fit()\n",
    "\n",
    "    #################### plotting steps below ################\n",
    "    p = myregression_results.params\n",
    "\n",
    "    sns.scatterplot(x='Age', y='Systolic_Blood_Pressure', data=bp)\n",
    "    x = np.linspace(np.min(X), np.max(X), 100)\n",
    "    plt.plot(x, p.const + p.Age * x)\n",
    "     ```\n",
    "   - **Assumptions:**\n",
    "     - Linearity: The relationship between predictor and outcome variables is linear\n",
    "     - Homoscedasticity: The variance of the errors is constant across all levels of the independent variables. In other words, the \"spread\" of the residuals should be the same throughout the range of the independent variables.\n",
    "     - Normality: The errors of the model (differences between predicted and actual values) follow a normal distribution.\n",
    "     - IID:  The observations are independent of each other. This means that the residuals (the differences between the observed and predicted values) are independent.\n",
    "     - No Multicollinearity: The independent variables are not too highly correlated with each other. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_8_'></a>[**Logistic Regression Wald's Test**](#toc0_)\n",
    "   - **Use Case:** This test is used when you want to determine if the coefficients of the logistic regression model are significantly different from zero. This helps to understand if a predictor variable has a significant effect on the outcome variable.\n",
    "   - **Examples:** Testing if the presence of West Nile Virus in mosquitoes is significantly affected by temperature or rainfall.\n",
    "   - **Hypothesis:**\n",
    "     - $H_0: β_i = 0$ (The predictor variable has no effect on the outcome variable)\n",
    "     - $H_a: β_i ≠ 0$ (The predictor variable has a significant effect on the outcome variable)\n",
    "   - **Formula:**\n",
    "     - $ W = \\frac{β_i}{SE_{β_i}}$\n",
    "     - Where $β_i$ is the coefficient of the predictor variable in the logistic regression model and $SE_{β_i}$ is the standard error of the coefficient.\n",
    "   - **Code:**\n",
    "     ```python\n",
    "     import statsmodels.api as sm\n",
    "\n",
    "     # Add constant to predictor variables\n",
    "     X = sm.add_constant(X)\n",
    "\n",
    "     # Fit logistic regression model\n",
    "     model = sm.Logit(y, X)\n",
    "     result = model.fit()\n",
    "\n",
    "     # Print summary statistics\n",
    "     print(result.summary())\n",
    "     ```\n",
    "   - **Assumptions:**\n",
    "     - The outcome variable is binary or ordinal (for logistic regression and ordinal logistic regression respectively).\n",
    "     - The predictor variables are linearly related to the log odds.\n",
    "     - There is no multicollinearity among the predictor variables.\n",
    "     - The sample size is sufficiently large for reliable results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc1_8_'></a>[**ANOVA**](#toc0_)\n",
    "   - **Use Case:** This test is used when you want to compare the means of more than two groups to see if they are significantly different from each other.\n",
    "   - **Examples:** Testing if the average height of plants grown with three different types of fertilizer is different.\n",
    "   - **Hypothesis:**\n",
    "     - $H_0$: The means of the groups are **equal**.\n",
    "     - $H_1$: The means of the groups are **not equal**.\n",
    "   - **Formula:**\n",
    "     - $$ F = \\frac{MS_{between}}{MS_{within}}$$\n",
    "       - Where $MS_{between}$ is the mean square between the groups and $MS_{within}$ is the mean square within the groups.\n",
    "     - $$ MS_{between} = \\frac{\\sum_{i=1}^k N_i (\\bar{Y_i} - \\bar{Y})^2}{k - 1} $$\n",
    "        - $\\bar Y_i$ is the mean for group $i$, \n",
    "        - $\\bar Y$ is the overall mean,\n",
    "        - $N_i$ is the size of group $i$, and\n",
    "        - k is the number of groups.\n",
    "      - $$ MS_{within} = \\frac{\\sum_{i=1}^k (N_i-1)s_i^2}{N - k}$$\n",
    "        - The only new notation here is $s^2_i$ which stands for the variance of group $i$.\n",
    "   - **Code:**\n",
    "     ```python\n",
    "     # first argument is an array, second argument is the array value to compare to\n",
    "     anova_test = stats.f_oneway(group1, group2, group3) \n",
    "     # outputs F statistic and a p-value\n",
    "     F_onewayResult(statistic=3.7113359882669763, pvalue=0.043589334959178244)\n",
    "     ```\n",
    "   - **Assumptions:**\n",
    "     - The samples are independent.\n",
    "     - The data in each group are normally distributed.\n",
    "     - The variances of the populations are equal.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_9_'></a>[**Tukey HSD Test**](#toc0_)\n",
    "   - **Use Case:** This test is used when you want to compare the means of more than two groups and find out which specific groups' means (compared with each other) are different.\n",
    "   - **Examples:** Testing which specific types of fertilizers result in different average plant heights.\n",
    "   - **Hypothesis:**\n",
    "     - $H_0$: The means of the groups are **equal**.\n",
    "     - $H_1$: The means of the groups are **not equal**.\n",
    "   - **Formula:**\n",
    "     - The Tukey HSD test uses a formula to calculate a range for comparison between the means of each pair of groups. If the difference between the means of a pair of groups falls within this range, then the means are considered not significantly different.\n",
    "   - **Code:**\n",
    "     ```python\n",
    "     from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "     \n",
    "     # first argument is the data, second argument is the groups, third argument is the level of significance\n",
    "     pairwise_tukeyhsd(endog=data, groups=groups, alpha=0.05).summary()\n",
    "     print(tukey)\n",
    "     # outputs a table with each pair of groups, the difference of their means, the lower and upper bounds of the comparison range, and whether the means are significantly different\n",
    "     ```\n",
    "   - **Assumptions:**\n",
    "     - The samples are independent.\n",
    "     - The data in each group are normally distributed.\n",
    "     - The variances of the populations are equal.\n",
    "     - The groups have the same sample size."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc1_10_'></a>[**Chi-Squared Test**](#toc0_)\n",
    "   - **Use Case:** This test is used when you want to see if there is a significant association between two categorical variables.\n",
    "   - **Examples:** Testing if there is an association between the type of trap and the presence of West Nile Virus.\n",
    "   - **Hypothesis test:** \n",
    "     - $H_0$: There is **no relationship** between the categorical variables.\n",
    "     - $H_A$: There is **a relationship** between the categorical variables.\n",
    "   - **Formula:**\n",
    "     - $ \\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i}$\n",
    "     - Where $O_i$ are the observed frequencies and $E_i$ are the expected frequencies.\n",
    "   - **Code:**\n",
    "     ```python\n",
    "     # first argument is an array\n",
    "     stats.chisquare(count_biased_list2)\n",
    "      \n",
    "     # Outputs the chi-square stat, and the p-value \n",
    "     Power_divergenceResult(statistic=11.866000000000001, pvalue=0.036670745046782215)\n",
    "\n",
    "     # first argument is an df\n",
    "     chi_squared_test = stats.chi2_contingency(observed) \n",
    "\n",
    "     # outputs chi-squared statistic, p-value, degrees of freedom, and expected frequencies\n",
    "     (chi2=10.48020691831597, p=0.005275729025274299, df=2, expected=array([[ 93.6,  98.4],\n",
    "       [ 20.4,  21.6]]))\n",
    "     ```\n",
    "   - **Assumptions:**\n",
    "     - The samples are independent.\n",
    "     - The categories are mutually exclusive.\n",
    "     - The sample size is large enough (expected frequency in each cell should be at least 5)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_6_'></a>[**Bootstrapping**](#toc0_)\n",
    "   - **Use Case:** This test is used when you want to estimate the sampling distribution of a statistic by generating many samples of the same size from the original data, with replacement.\n",
    "   - **Examples:** Estimating the mean height of a population based on a sample.\n",
    "   - **Hypothesis:**\n",
    "     - $$H_0: \\text{The sample statistic is equal to the population statistic}$$\n",
    "     - $$H_1: \\text{The sample statistic is not equal to the population statistic}$$\n",
    "   - **Procedure:**\n",
    "     - Draw a sample with replacement from the original data (same size as original data).\n",
    "     - Compute the statistic of interest for this bootstrap sample.\n",
    "     - Repeat the process many times (commonly 1000 or 10000 times), each time computing the statistic of interest.\n",
    "     - Use the distribution of these bootstrap statistics to estimate the standard error, confidence intervals, or significance tests.\n",
    "   - **Code:**\n",
    "     ```python\n",
    "     # numpy's random.choice function can be used to generate bootstrap samples\n",
    "     bootstrap_sample = np.random.choice(original_data, size=len(original_data), replace=True)\n",
    "     # compute statistic of interest on bootstrap_sample\n",
    "     ```\n",
    "   - **Assumptions:**\n",
    "     - The original sample is representative of the population.\n",
    "     - The bootstrap samples are drawn independently and with replacement.\n",
    "     - The number of bootstrap samples is large enough to approximate the sampling distribution."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_10_'></a>[**Spearman Coefficient T-Test**](#toc0_)\n",
    "   - **Use Case:** This test is used when you want to determine if there is a significant monotonic relationship between two variables. It is a non-parametric test that does not assume linearity or normally distributed data.\n",
    "   - **Examples:** Testing if the rank of mosquito population size is related to the rank of rainfall amount.\n",
    "   - **Hypothesis:**\n",
    "     - $$H_0: \\rho = 0$$\n",
    "     - $$H_1: \\rho \\neq 0$$\n",
    "   - **Formula:**\n",
    "     - Spearman's rank correlation coefficient is calculated using the following formula:\n",
    "     - $ρ_s = 1 - \\frac{6 ∑d_i^2}{n(n^2 - 1)}$\n",
    "     - Where $d_i$ is the difference between the two ranks of each observation and $n$ is the number of observations.\n",
    "   - **Code:**\n",
    "     ```python\n",
    "     from scipy import stats\n",
    "\n",
    "     # Calculate Spearman's rank correlation coefficient and the p-value\n",
    "     rho, p_value = stats.spearmanr(x, y)\n",
    "\n",
    "     print(f\"Spearman's rank correlation coefficient: {rho}\")\n",
    "     print(f\"P-value: {p_value}\")\n",
    "     ```\n",
    "   - **Assumptions:**\n",
    "     - The variables are ordinal, interval or ratio.\n",
    "     - The relationship between the variables is monotonic, meaning that the variables tend to change together, but not necessarily at a constant rate.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc1_11_'></a>[**Point Biserial T-Test**](#toc0_)\n",
    "   - **Use Case:** This test is used when you want to determine if there is a significant difference in a continuous variable between two groups. One variable should be binary and the other should be continuous.\n",
    "   - **Examples:** Testing if the average mosquito population size is different between two different trap types.\n",
    "   - **Hypothesis:**\n",
    "     - $$H_0: \\rho = 0$$\n",
    "     - $$H_1: \\rho \\neq 0$$\n",
    "   - **Formula:**\n",
    "     - Point Biserial correlation coefficient is calculated using the following formula:\n",
    "     - $r_{pb} = \\frac{M_1 - M_0}{s_n} \\sqrt{\\frac{n_1 n_0}{n^2}}$\n",
    "     - Where $M_1$ and $M_0$ are the means of the two groups, $s_n$ is the standard deviation, $n_1$ and $n_0$ are the sizes of the two groups, and $n$ is the total sample size.\n",
    "   - **Code:**\n",
    "     ```python\n",
    "     from scipy import stats\n",
    "\n",
    "     # Calculate Point Biserial correlation coefficient and the p-value\n",
    "     r, p_value = stats.pointbiserialr(x, y)\n",
    "\n",
    "     print(f\"Point Biserial correlation coefficient: {r}\")\n",
    "     print(f\"P-value: {p_value}\")\n",
    "     ```\n",
    "   - **Assumptions:**\n",
    "     - The continuous variable is approximately normally distributed within each group.\n",
    "     - The variances of the continuous variable are equal across the two groups (homogeneity of variances).\n",
    "     - The binary variable divides the participants into two independent groups."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Two Tailed vs One Tailed Tests](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc2_1_'></a>[**One-Tailed Hypothesis Test**](#toc0_)\n",
    "   - **Use Case:** This test is used when the direction of the relationship between variables is known or hypothesized. It tests whether the value of a parameter is greater than or less than the hypothesized value.\n",
    "     - You should only use this test if you have a good reason to believe that the parameter is greater than or less than the hypothesized value. Otherwise, you should use a two-tailed test.\n",
    "     - You can also use this test for further exploration of a hypothesis *with a new dataset*.\n",
    "   - **Examples:** Testing if the average height of a certain type of plant is greater than 10 cm.\n",
    "   - **Hypothesis test:** \n",
    "     - $H_0$: The parameter is less than or equal to (or greater than or equal to) the hypothesized value.\n",
    "     - $H_A$: The parameter is greater than (or less than) the hypothesized value.\n",
    "   - **Formula:**\n",
    "     - Depends on the specific test being used (e.g., t-test, z-test, etc.)\n",
    "   - **Code:**\n",
    "     ```python\n",
    "     # For a one-sample t-test\n",
    "     stats.ttest_1samp(sample, popmean)\n",
    "     ```\n",
    "   - **Assumptions:**\n",
    "     - Depends on the specific test being used. For a t-test, the assumptions include independence of observations, normality, and (for a two-sample t-test) equal variances.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc2_2_'></a>[**Two-Tailed Hypothesis Test**](#toc0_)\n",
    "   - **Use Case:** This test is used when the direction of the relationship between variables is not known or specified. It tests whether the value of a parameter is different (either greater or less) than the hypothesized value.\n",
    "     - This is the STANDARD and most common type of test. You need to have a good reason to use a one-tailed test.\n",
    "   - **Examples:** Testing if the average height of a certain type of plant is different from 10 cm.\n",
    "   - **Hypothesis test:** \n",
    "     - $H_0$: The parameter is equal to the hypothesized value.\n",
    "     - $H_A$: The parameter is not equal to the hypothesized value.\n",
    "   - **Formula:**\n",
    "     - Depends on the specific test being used (e.g., t-test, z-test, etc.)\n",
    "   - **Code:**\n",
    "     ```python\n",
    "     # For a one-sample t-test\n",
    "     stats.ttest_samp(sample, popmean)\n",
    "     ```\n",
    "   - **Assumptions:**\n",
    "     - Depends on the specific test being used. For a t-test, the assumptions include independence of observations, normality, and (for a two-sample t-test) equal variances."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
