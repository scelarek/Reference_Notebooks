{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Hypothesis Tests with Formulas, Code, Assumptions](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Hypothesis Tests with Formulas, Code, Assumptions](#toc1_1_)    \n",
    "  - [**One-Sample T-Test**](#toc1_2_)    \n",
    "  - [**Two-Sample T-Test (Unpaired)**](#toc1_3_)    \n",
    "  - [**Two-Sample T-Test (Paired)**](#toc1_4_)    \n",
    "  - [**Proportion Z Test**](#toc1_5_)    \n",
    "  - [**Correlation Coefficient T-Test**](#toc1_6_)    \n",
    "  - [**Linear Regression T-Test**](#toc1_7_)    \n",
    "  - [**Logistic Regression Wald's Test**](#toc1_8_)    \n",
    "  - [**ANOVA**](#toc1_9_)    \n",
    "  - [**Tukey HSD Test**](#toc1_10_)    \n",
    "  - [**Chi-Squared Test**](#toc1_11_)    \n",
    "  - [**Bootstrapping**](#toc1_12_)    \n",
    "  - [**Spearman Coefficient T-Test**](#toc1_13_)    \n",
    "  - [**Point Biserial T-Test**](#toc1_14_)    \n",
    "- [Two Tailed vs One Tailed Tests](#toc2_)    \n",
    "  - [**One-Tailed Hypothesis Test**](#toc2_1_)    \n",
    "  - [**Two-Tailed Hypothesis Test**](#toc2_2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[**One-Sample T-Test**](#toc0_)\n",
    "   - **Use Case:** This test is used when you want to compare the mean of a sample to a known value or a theoretical expectation.\n",
    "   - **Examples:** Testing if the average height of a certain type of plant is different from 10 cm.\n",
    "   - **Hypothesis Testing:**  \n",
    "     - $$H0: \\mu_{test} = 0$$\n",
    "     - $$H1: \\mu_{test} \\neq 0$$\n",
    "   - **Formula:**\n",
    "     - $ t = \\frac{\\overline{x} - \\mu_{test}}{\\left(s\\,\\big/ \\sqrt{n}\\right)}$\n",
    "   - **Code:**\n",
    "     ```python\n",
    "     # first argument is an array, second argument is the hypothesis value\n",
    "     one_sample_test = stats.ttest_1samp(store1, 14.5)\n",
    "     # outputs t-test statistic and a p-value\n",
    "     TtestResult(statistic=7.203710690696487, pvalue=1.1660253276676903e-10, df=99)\n",
    "     ```\n",
    "<div style=\"background-color: #e0e0e0; padding: 10px; border-radius: 10px; border: 1px solid #333;\">\n",
    "\n",
    "- **Assumptions:**  \n",
    "  1. **IID** - The samples are **independent** and from the **same population**. \n",
    "  2. **Randomness** - The samples are **random** and **representative** of the underlying population. \n",
    "       - The variance and mean of the sample and underlying population are the same.\n",
    "  3.  **Normality** - The samples follow a normal distribution via the Central Limit Theorem. This has to meet one of the following conditions:\n",
    "       - Sample itself is normally distributed\n",
    "       - Sample size is large enough (n > 30)\n",
    "       - It passes some other test for normality\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## <a id='toc1_3_'></a>[**Two-Sample T-Test (Unpaired)**](#toc0_)\n",
    "   - **Use Case:** This test is used when you want to compare the means of two independent groups to see if they are significantly different from each other.\n",
    "   - **Examples:** Testing if the average height of plants grown with two different types of fertilizer is different.\n",
    "   - **Hypothesis:**  \n",
    "     - $$H0: \\mu_1 -  \\mu_2 = 0$$\n",
    "     - $$H1: \\mu_1 -  \\mu_2 \\neq 0$$\n",
    "   - **Formula:**\n",
    "     - $ t = \\frac{(\\overline{X}_1 - \\overline{X}_2) - (\\mu_1 - \\mu_2)}{s_p \\sqrt{\\frac{1}{n_1}+\\frac{1}{n_2}}}$\n",
    "     - Where the $\\overline{X}_1$ and $\\overline{X}_2$ are the sample means, $(\\mu_1 - \\mu_2)$ is the population difference you want to test against and $s_p$ is the [pooled standard deviation](https://en.wikipedia.org/wiki/Pooled_variance) of the samples.\n",
    "     - $s_p = \\sqrt{\\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}}$\n",
    "   - **Code:**\n",
    "     ```python\n",
    "     # first argument is an array, second argument is the array value to compare to\n",
    "     two_sample_test = stats.ttest_ind(store_suburbs, store_downtown) \n",
    "     # outputs t-test statistic and a p-value\n",
    "     Ttest_indResult(statistic=-2.3843100564172697, pvalue=0.01805557370062323)\n",
    "     ```\n",
    "   - **Assumptions:**\n",
    "     - Data points in each group are independent of each other.\n",
    "     - The means of both samples come from a normal sampling distribution.\n",
    "       - Sample itself is normally distributed\n",
    "       - Sample size is large enough (n > 30)\n",
    "     - Data in group A are independent from data in group B.\n",
    "     - Variances of both populations are identical.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc1_4_'></a>[**Two-Sample T-Test (Paired)**](#toc0_)\n",
    "   - **Use Case:** This test is used when you want to compare the means of the same group at two different times (for example, before and after a treatment).\n",
    "   - **Examples:** Testing the average spend of the same customers at two different stores.\n",
    "   - **Hypothesis:**  \n",
    "     - $$H0: \\mu_{test1} - \\mu_{test2} = 0$$\n",
    "     - $$H1: \\mu_{test1} - \\mu_{test2} \\neq 0$$\n",
    "   - **Formula:**\n",
    "     - $ t = \\frac{\\overline{X_D} - µ_{test}}{\\frac{s_D}{\\sqrt{n}}} $\n",
    "     - Where $X_D$ is the set of differences between paired samples, $µ_{test}$ is our mean difference that we want to compare to (0 in this case), $s_D$ is difference sample standard deviation, and n is the number of samples.\n",
    "   - **Code:**\n",
    "     ```python\n",
    "     # first argument is an array, second argument is the array value to compare to\n",
    "     stats.ttest_rel(store_suburbs, store_downtown)\n",
    "     # outputs t-test statistic and a p-value\n",
    "     TtestResult(statistic=-2.4153163510165245, pvalue=0.017556013707886925, df=99)\n",
    "     ```\n",
    "   - **Assumptions:**\n",
    "     - Data points in each group are independent of each other.\n",
    "     - Data points in group A and B are paired/matched.\n",
    "     - The mean of the samples differences comes from a normal sampling distribution.\n",
    "       - Sample itself is normally distributed\n",
    "       - Sample size is large enough (n > 30)\n",
    "     - Variances of both populations are identical.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc1_5_'></a>[**Proportion Z Test**](#toc0_)\n",
    "   - **Use Case:** This test is used when you want to compare the proportions of two groups to see if they are significantly different from each other.\n",
    "   - **Examples:** Testing if the proportion of customers who bought a product is different between two stores.\n",
    "   - **Hypothesis:**  \n",
    "     - $$H0: p_1 = p_2$$\n",
    "     - $$H1: p_1 \\neq p_2$$\n",
    "   - **Formula:**\n",
    "     - $ z = \\frac{p_1 - p_2}{\\sqrt{p(1 - p)(\\frac{1}{n_1} + \\frac{1}{n_2})}}$\n",
    "     - Where $p_1$ and $p_2$ are the sample proportions, $p$ is the pooled sample proportion, and $n_1$ and $n_2$ are the sample sizes.\n",
    "   - **Code:**\n",
    "     ```python\n",
    "     # first argument is an array, second argument is the array value to compare to\n",
    "     z_test = stats.proportions_ztest([successes_in_a, successes_in_b], [count_of_a, count_of_b]) \n",
    "     # outputs z-test statistic and a p-value\n",
    "     (statistic=-1.705800384635185, pvalue=0.08806845338765186)\n",
    "     ```\n",
    "\n",
    "<div style=\"background-color: #e0e0e0; padding: 10px; border-radius: 10px; border: 1px solid #333;\">\n",
    "\n",
    "**Assumptions:** \n",
    "\n",
    "1. **IID** - The samples are **independent** and from the **same population**. \n",
    "2. **Randomness** - The samples are **random** and **representative** of the underlying population. \n",
    "      - The variance and mean of the sample and underlying population are the same.\n",
    "3.  **Normality** - The samples follow a normal distribution via the Central Limit Theorem. This has to meet one of the following conditions:\n",
    "      - Sample itself is normally distributed\n",
    "      - Sample size is large enough ($n*p > 5$ and $n(1-p) > 5$) for both groups\n",
    "      - Up to 3 Standard Deviations of each proportion are completely contained with 0-1. $[p-3s_w, p+3s_w] \\subseteq [0,1]$\n",
    "      - It passes some other test for normality\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc1_6_'></a>[**Correlation Coefficient T-Test**](#toc0_)\n",
    "   - **Use Case:** This test is used when you want to determine if there is a significant correlation between two variables.\n",
    "   - **Examples:** Testing if there is a correlation between the amount of rainfall and the number of mosquitoes.\n",
    "   - **Hypothesis:**\n",
    "     - $$H_0: \\rho = 0$$\n",
    "     - $$H_1: \\rho \\neq 0$$\n",
    "   - **Formula:**\n",
    "     - $ t = \\frac{r\\sqrt{n-2}}{\\sqrt{1-r^2}}$\n",
    "     - Where $r$ is the sample correlation coefficient and $n$ is the sample size.\n",
    "   - **Code:**\n",
    "     ```python\n",
    "     # first argument is an array, second argument is the array value to compare to\n",
    "     correlation_test = stats.pearsonr(x, y) \n",
    "     # outputs correlation coefficient and a p-value\n",
    "     (correlation=0.8658002752562366, pvalue=0.011807351043126281)\n",
    "     ```\n",
    "   - **Assumptions:**\n",
    "     - The variables are continuous and numeric.\n",
    "     - The variables are linearly related.\n",
    "     - The data is homoscedastic, meaning the variance of the residuals (or \"errors\") is constant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_7_'></a>[**Linear Regression T-Test**](#toc0_)\n",
    "   - **Use Case:** This test is used when you want to determine if the coefficients of the linear regression model are significantly different from zero. This helps to understand if a predictor variable has a significant effect on the outcome variable.\n",
    "   - **Examples:** Testing if the number of mosquitoes increases with the amount of rainfall.\n",
    "   - **Hypothesis:**\n",
    "     - $H_0: β_i = 0$ (The predictor variable has no effect on the outcome variable)\n",
    "     - $H_a: β_i ≠ 0$ (The predictor variable has a significant effect on the outcome variable)\n",
    "   - **Formula:**\n",
    "     - $ t = \\frac{β_i}{SE_{β_i}}$\n",
    "     - Where $β_i$ is the coefficient of the predictor variable in the linear regression model and $SE_{β_i}$ is the standard error of the coefficient.\n",
    "   - **Code:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mstatsmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msm\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m bp \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mbp.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[39m#seperate data into X (independant) and Y (dependant)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m X \u001b[39m=\u001b[39m bp[\u001b[39m'\u001b[39m\u001b[39mAge\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "bp = pd.read_csv('bp.csv')\n",
    "\n",
    "\n",
    "#seperate data into X (independant) and Y (dependant)\n",
    "X = bp['Age']\n",
    "y = bp['Systolic_Blood_Pressure']\n",
    "\n",
    "# add constant\n",
    "X_withconstant = sm.add_constant(X)\n",
    "\n",
    "# Instantiate Model\n",
    "myregression = sm.OLS(y, X_withconstant)\n",
    "\n",
    "# Fit Model (this returns a seperate object with the parameters)\n",
    "myregression_results = myregression.fit()\n",
    "\n",
    "#################### plotting steps below ################\n",
    "p = myregression_results.params\n",
    "\n",
    "sns.scatterplot(x='Age', y='Systolic_Blood_Pressure', data=bp)\n",
    "x = np.linspace(np.min(X), np.max(X), 100)\n",
    "plt.plot(x, p.const + p.Age * x)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e0e0e0; padding: 10px; border-radius: 10px; border: 1px solid #333;\">\n",
    "\n",
    "**Assumptions**:\n",
    "\n",
    "- **Independence and Identically Distributed**: The observations and their corresponding residuals should be independent of each other. Also the data is assumed to be from the same probability distribution or population.\n",
    "\n",
    "- **Linearity**: The relationship between the independent and dependent variables should be linear.  \n",
    "\n",
    "- **No Multicollinearity**: The independent variables are not too highly correlated with each other.  \n",
    "\n",
    "- **Normality of Residuals**: The errors of the model (differences between predicted and actual values) follow a normal distribution.\n",
    "\n",
    "- **Homoscedasticity**: The variance of the errors is constant across all levels of the independent variables. In other words, the \"spread\" of the residuals should be the same throughout the range of the independent variables.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_8_'></a>[**Logistic Regression Wald's Test**](#toc0_)\n",
    "   - **Use Case:** This test is used when you want to determine if the coefficients of the logistic regression model are significantly different from zero. This helps to understand if a predictor variable has a significant effect on the outcome variable.\n",
    "   - **Examples:** Testing if the presence of West Nile Virus in mosquitoes is significantly affected by temperature or rainfall.\n",
    "   - **Hypothesis:**\n",
    "     - $H_0: β_i = 0$ (The predictor variable has no effect on the outcome variable)\n",
    "     - $H_a: β_i ≠ 0$ (The predictor variable has a significant effect on the outcome variable)\n",
    "   - **Formula:**\n",
    "     - $ W = \\frac{β_i}{SE_{β_i}}$\n",
    "     - Where $β_i$ is the coefficient of the predictor variable in the logistic regression model and $SE_{β_i}$ is the standard error of the coefficient.\n",
    "   - **Code:**\n",
    "     ```python\n",
    "     import statsmodels.api as sm\n",
    "\n",
    "     # Add constant to predictor variables\n",
    "     X = sm.add_constant(X)\n",
    "\n",
    "     # Fit logistic regression model\n",
    "     model = sm.Logit(y, X)\n",
    "     result = model.fit()\n",
    "\n",
    "     # Print summary statistics\n",
    "     print(result.summary())\n",
    "     ```\n",
    "<div style=\"background-color: #e0e0e0; padding: 10px; border-radius: 10px; border: 1px solid #333;\">\n",
    "\n",
    "**Assumptions for Logistic Regression**:\n",
    "- **Independence and Identically Distributed**: The observations and the corresponding residuals should be independent of each other. Also the data is assumed to be from the same probability distribution or population.\n",
    "\n",
    "- **Discrete Outcome**: The dependent variable should be binary in binary logistic regression. One can also do multi-class logistic regression, using the one vs one or one vs all approach.\n",
    "\n",
    "- **Linearity of Independent Variables and Log Odds**: The independent variables are linearly related to the log odds. This does not mean that the relationship between the independent and dependent variables is linear, but that the logit transformation of the dependent variable results in a linear relationship.\n",
    "\n",
    "- **Absence of Multicollinearity**: The independent variables should not be too highly correlated with each other. This assumption is similar to the assumption in multiple linear regression. Multicollinearity can lead to unstable estimates and decreased interpretability of the model.\n",
    "\n",
    "- **Class Balance and Normality**: Logistic regression requires a large sample size to achieve reliable results. While there is no definitive rule for the minimum sample size, a common guideline is that logistic regression requires at least 10 cases with the least frequent outcome for each independent variable in the model.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc1_9_'></a>[**ANOVA**](#toc0_)\n",
    "   - **Use Case:** This test is used when you want to compare the means of more than two groups to see if they are significantly different from each other.\n",
    "   - **Examples:** Testing if the average height of plants grown with three different types of fertilizer is different.\n",
    "   - **Hypothesis:**\n",
    "     - $H_0$: The means of the groups are **equal**.\n",
    "     - $H_1$: The means of the groups are **not equal**.\n",
    "   - **Formula:**\n",
    "     - $$ F = \\frac{MS_{between}}{MS_{within}}$$\n",
    "       - Where $MS_{between}$ is the mean square between the groups and $MS_{within}$ is the mean square within the groups.\n",
    "     - $$ MS_{between} = \\frac{\\sum_{i=1}^k N_i (\\bar{Y_i} - \\bar{Y})^2}{k - 1} $$\n",
    "        - $\\bar Y_i$ is the mean for group $i$, \n",
    "        - $\\bar Y$ is the overall mean,\n",
    "        - $N_i$ is the size of group $i$, and\n",
    "        - k is the number of groups.\n",
    "      - $$ MS_{within} = \\frac{\\sum_{i=1}^k (N_i-1)s_i^2}{N - k}$$\n",
    "        - The only new notation here is $s^2_i$ which stands for the variance of group $i$.\n",
    "   - **Code:**\n",
    "     ```python\n",
    "     # first argument is an array, second argument is the array value to compare to\n",
    "     anova_test = stats.f_oneway(group1, group2, group3) \n",
    "     # outputs F statistic and a p-value\n",
    "     F_onewayResult(statistic=3.7113359882669763, pvalue=0.043589334959178244)\n",
    "     ```\n",
    "   - **Assumptions:**\n",
    "     - The samples are independent.\n",
    "     - The data in each group are normally distributed.\n",
    "     - The variances of the populations are equal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_10_'></a>[**Tukey HSD Test**](#toc0_)\n",
    "   - **Use Case:** This test is used when you want to compare the means of more than two groups and find out which specific groups' means (compared with each other) are different.\n",
    "   - **Examples:** Testing which specific types of fertilizers result in different average plant heights.\n",
    "   - **Hypothesis:**\n",
    "     - $H_0$: The means of the groups are **equal**.\n",
    "     - $H_1$: The means of the groups are **not equal**.\n",
    "   - **Formula:**\n",
    "     - The Tukey HSD test uses a formula to calculate a range for comparison between the means of each pair of groups. If the difference between the means of a pair of groups falls within this range, then the means are considered not significantly different.\n",
    "   - **Code:**\n",
    "     ```python\n",
    "     from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "     \n",
    "     # first argument is the data, second argument is the groups, third argument is the level of significance\n",
    "     pairwise_tukeyhsd(endog=data, groups=groups, alpha=0.05).summary()\n",
    "     print(tukey)\n",
    "     # outputs a table with each pair of groups, the difference of their means, the lower and upper bounds of the comparison range, and whether the means are significantly different\n",
    "     ```\n",
    "   - **Assumptions:**\n",
    "     - The samples are independent.\n",
    "     - The data in each group are normally distributed.\n",
    "     - The variances of the populations are equal.\n",
    "     - The groups have the same sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc1_11_'></a>[**Chi-Squared Test**](#toc0_)\n",
    "   - **Use Case:** This test is used when you want to see if there is a significant association between two categorical variables.\n",
    "   - **Examples:** Testing if there is an association between the type of trap and the presence of West Nile Virus.\n",
    "   - **Hypothesis test:** \n",
    "     - $H_0$: There is **no relationship** between the categorical variables.\n",
    "     - $H_A$: There is **a relationship** between the categorical variables.\n",
    "   - **Formula:**\n",
    "     - $ \\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i}$\n",
    "     - Where $O_i$ are the observed frequencies and $E_i$ are the expected frequencies.\n",
    "   - **Code:**\n",
    "     ```python\n",
    "     # first argument is an array\n",
    "     stats.chisquare(count_biased_list2)\n",
    "      \n",
    "     # Outputs the chi-square stat, and the p-value \n",
    "     Power_divergenceResult(statistic=11.866000000000001, pvalue=0.036670745046782215)\n",
    "\n",
    "     # first argument is an df\n",
    "     chi_squared_test = stats.chi2_contingency(observed) \n",
    "\n",
    "     # outputs chi-squared statistic, p-value, degrees of freedom, and expected frequencies\n",
    "     (chi2=10.48020691831597, p=0.005275729025274299, df=2, expected=array([[ 93.6,  98.4],\n",
    "       [ 20.4,  21.6]]))\n",
    "     ```\n",
    "   - **Assumptions:**\n",
    "     - The samples are independent.\n",
    "     - The categories are mutually exclusive.\n",
    "     - The sample size is large enough (expected frequency in each cell should be at least 5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_12_'></a>[**Bootstrapping**](#toc0_)\n",
    "   - **Use Case:** This test is used when you want to estimate the sampling distribution of a statistic by generating many samples of the same size from the original data, with replacement.\n",
    "   - **Examples:** Estimating the mean height of a population based on a sample.\n",
    "   - **Hypothesis:**\n",
    "     - $$H_0: \\text{The sample statistic is equal to the population statistic}$$\n",
    "     - $$H_1: \\text{The sample statistic is not equal to the population statistic}$$\n",
    "   - **Procedure:**\n",
    "     - Draw a sample with replacement from the original data (same size as original data).\n",
    "     - Compute the statistic of interest for this bootstrap sample.\n",
    "     - Repeat the process many times (commonly 1000 or 10000 times), each time computing the statistic of interest.\n",
    "     - Use the distribution of these bootstrap statistics to estimate the standard error, confidence intervals, or significance tests.\n",
    "   - **Code:**\n",
    "     ```python\n",
    "     # numpy's random.choice function can be used to generate bootstrap samples\n",
    "     bootstrap_sample = np.random.choice(original_data, size=len(original_data), replace=True)\n",
    "     # compute statistic of interest on bootstrap_sample\n",
    "     ```\n",
    "   - **Assumptions:**\n",
    "     - The original sample is representative of the population.\n",
    "     - The bootstrap samples are drawn independently and with replacement.\n",
    "     - The number of bootstrap samples is large enough to approximate the sampling distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_13_'></a>[**Spearman Coefficient T-Test**](#toc0_)\n",
    "   - **Use Case:** This test is used when you want to determine if there is a significant monotonic relationship between two variables. It is a non-parametric test that does not assume linearity or normally distributed data.\n",
    "   - **Examples:** Testing if the rank of mosquito population size is related to the rank of rainfall amount.\n",
    "   - **Hypothesis:**\n",
    "     - $$H_0: \\rho = 0$$\n",
    "     - $$H_1: \\rho \\neq 0$$\n",
    "   - **Formula:**\n",
    "     - Spearman's rank correlation coefficient is calculated using the following formula:\n",
    "     - $ρ_s = 1 - \\frac{6 ∑d_i^2}{n(n^2 - 1)}$\n",
    "     - Where $d_i$ is the difference between the two ranks of each observation and $n$ is the number of observations.\n",
    "   - **Code:**\n",
    "     ```python\n",
    "     from scipy import stats\n",
    "\n",
    "     # Calculate Spearman's rank correlation coefficient and the p-value\n",
    "     rho, p_value = stats.spearmanr(x, y)\n",
    "\n",
    "     print(f\"Spearman's rank correlation coefficient: {rho}\")\n",
    "     print(f\"P-value: {p_value}\")\n",
    "     ```\n",
    "\n",
    "<div style=\"background-color: #e0e0e0; padding: 10px; border-radius: 10px; border: 1px solid #333;\">\n",
    "\n",
    "**Assumptions**:\n",
    "\n",
    " - **Measurability**: The variables are ordinal, interval or ratio.\n",
    " - **Monotonicity**: The relationship between the variables is monotonic, meaning that the variables tend to change together, but not necessarily at a constant rate.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc1_14_'></a>[**Point Biserial T-Test**](#toc0_)\n",
    "   - **Use Case:** This test is used when you want to determine if there is a significant difference in a continuous variable between two groups. One variable should be binary and the other should be continuous.\n",
    "   - **Examples:** Testing if the average mosquito population size is different between two different trap types.\n",
    "   - **Hypothesis:**\n",
    "     - $$H_0: \\rho = 0$$\n",
    "     - $$H_1: \\rho \\neq 0$$\n",
    "   - **Formula:**\n",
    "     - Point Biserial correlation coefficient is calculated using the following formula:\n",
    "     - $r_{pb} = \\frac{M_1 - M_0}{s_n} \\sqrt{\\frac{n_1 n_0}{n^2}}$\n",
    "     - Where $M_1$ and $M_0$ are the means of the two groups, $s_n$ is the standard deviation, $n_1$ and $n_0$ are the sizes of the two groups, and $n$ is the total sample size.\n",
    "   - **Code:**\n",
    "     ```python\n",
    "     from scipy import stats\n",
    "\n",
    "     # Calculate Point Biserial correlation coefficient and the p-value\n",
    "     r, p_value = stats.pointbiserialr(x, y)\n",
    "\n",
    "     print(f\"Point Biserial correlation coefficient: {r}\")\n",
    "     print(f\"P-value: {p_value}\")\n",
    "     ```\n",
    "\n",
    "<div style=\"background-color: #e0e0e0; padding: 10px; border-radius: 10px; border: 1px solid #333;\">\n",
    "\n",
    "**Assumptions**:\n",
    "\n",
    "1. **Binary variable**: One of the variables should be dichotomous, i.e., it should take only two possible outcomes (0/1, True/False, etc.).\n",
    "2. **Normality**: The continuous variable should be approximately normally distributed for each category of the binary variable.\n",
    "3. **Linearity**: The relationship between the continuous and binary variables should be linear, \n",
    "4. **Homoscedasticity**: The variances of the continuous variable for each category of the binary variable should be equal (homoscedasticity).\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Two Tailed vs One Tailed Tests](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc2_1_'></a>[**One-Tailed Hypothesis Test**](#toc0_)\n",
    "   - **Use Case:** This test is used when the direction of the relationship between variables is known or hypothesized. It tests whether the value of a parameter is greater than or less than the hypothesized value.\n",
    "     - You should only use this test if you have a good reason to believe that the parameter is greater than or less than the hypothesized value. Otherwise, you should use a two-tailed test.\n",
    "     - You can also use this test for further exploration of a hypothesis *with a new dataset*.\n",
    "   - **Examples:** Testing if the average height of a certain type of plant is greater than 10 cm.\n",
    "   - **Hypothesis test:** \n",
    "     - $H_0$: The parameter is less than or equal to (or greater than or equal to) the hypothesized value.\n",
    "     - $H_A$: The parameter is greater than (or less than) the hypothesized value.\n",
    "   - **Formula:**\n",
    "     - Depends on the specific test being used (e.g., t-test, z-test, etc.)\n",
    "   - **Code:**\n",
    "     ```python\n",
    "     # For a one-sample t-test\n",
    "     stats.ttest_1samp(sample, popmean)\n",
    "     ```\n",
    "   - **Assumptions:**\n",
    "     - Depends on the specific test being used. For a t-test, the assumptions include independence of observations, normality, and (for a two-sample t-test) equal variances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc2_2_'></a>[**Two-Tailed Hypothesis Test**](#toc0_)\n",
    "   - **Use Case:** This test is used when the direction of the relationship between variables is not known or specified. It tests whether the value of a parameter is different (either greater or less) than the hypothesized value.\n",
    "     - This is the STANDARD and most common type of test. You need to have a good reason to use a one-tailed test.\n",
    "   - **Examples:** Testing if the average height of a certain type of plant is different from 10 cm.\n",
    "   - **Hypothesis test:** \n",
    "     - $H_0$: The parameter is equal to the hypothesized value.\n",
    "     - $H_A$: The parameter is not equal to the hypothesized value.\n",
    "   - **Formula:**\n",
    "     - Depends on the specific test being used (e.g., t-test, z-test, etc.)\n",
    "   - **Code:**\n",
    "     ```python\n",
    "     # For a one-sample t-test\n",
    "     stats.ttest_samp(sample, popmean)\n",
    "     ```\n",
    "   - **Assumptions:**\n",
    "     - Depends on the specific test being used. For a t-test, the assumptions include independence of observations, normality, and (for a two-sample t-test) equal variances."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
