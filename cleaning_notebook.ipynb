{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [**High Level Data Cleaning Process**](#toc1_)    \n",
    "  - [***Gather***](#toc1_1_)    \n",
    "  - [***Assess***](#toc1_2_)    \n",
    "  - [***Clean***](#toc1_3_)    \n",
    "  - [**Clean Data has Two Dimensions:**](#toc1_4_)    \n",
    "      - [***Cleanliness***](#toc1_4_1_1_)    \n",
    "      - [***Tidiness:***](#toc1_4_1_2_)    \n",
    "  - [**Order for Addressing Problems:**](#toc1_5_)    \n",
    "- [Demo](#toc2_)    \n",
    "  - [Gathering](#toc2_1_)    \n",
    "    - [Setup](#toc2_1_1_)    \n",
    "    - [Load](#toc2_1_2_)    \n",
    "  - [Assess](#toc2_2_)    \n",
    "    - [Programmatic Assessment](#toc2_2_1_)    \n",
    "    - [Visual Assessment](#toc2_2_2_)    \n",
    "    - [Issues to Resolve](#toc2_2_3_)    \n",
    "      - [Quality issues](#toc2_2_3_1_)    \n",
    "      - [Tidiness issues](#toc2_2_3_2_)    \n",
    "  - [Clean](#toc2_3_)    \n",
    "    - [Issue #1:](#toc2_3_1_)    \n",
    "      - [Define:](#toc2_3_1_1_)    \n",
    "      - [Code](#toc2_3_1_2_)    \n",
    "      - [Test](#toc2_3_1_3_)    \n",
    "    - [Issue #2:....](#toc2_3_2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[**High Level Data Cleaning Process**](#toc0_)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc1_1_'></a>[***Gather***](#toc0_)\n",
    "1. **Setup Libraries**: Import all the necessary libraries that you will need for your data analysis. This typically includes libraries like pandas, numpy, matplotlib, seaborn, etc. Setting up libraries at the beginning of your script ensures you have all the tools you need for analysis, visualization, and modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. **Load in Data**: Read in the data from your source file (like a CSV, Excel, SQL database, etc.) into a DataFrame, which is a type of data structure provided by the pandas library. This is your starting point for the data analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('data.csv')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[***Assess***](#toc0_)\n",
    "1. **Programmatic Assessment**: Review the data using code. This includes methods like  `df.info()`, `df.describe()`, etc. These methods help you understand the structure of the data, the types of variables you have, and basic statistics of the variables.\n",
    "\n",
    "2. **Visual Assessment**: Review the data by scrolling through it in a spreadsheet or using `df.head()`, `df.tail()`. This can help you spot anomalies or patterns in the data that may not be immediately apparent through programmatic assessment.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc1_3_'></a>[***Clean***](#toc0_)\n",
    "1. **Define**: Define how you will clean the issue in words. This is your plan of action for dealing with the identified data quality and tidiness issues. It's important to define this plan before you start coding to ensure you have a clear understanding of the steps you need to take.\n",
    "\n",
    "2. **Code**: Convert your definitions into executable code. This is where you implement your plan. This could involve writing functions to clean the data, using built-in pandas functions, or using other data cleaning libraries.\n",
    "\n",
    "3. **Test**: Test your data to ensure your code was implemented correctly. This involves checking your cleaned data to confirm that it's in the expected format and that the data quality and tidiness issues have been addressed. This can be done using a combination of programmatic and visual assessments."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_4_'></a>[**Clean Data has Two Dimensions:**](#toc0_)\n",
    "\n",
    "#### <a id='toc1_4_1_1_'></a>[Cleanliness](#toc0_)\n",
    "1. **Completeness**: Do we have all of the records that we should?\n",
    "2. **Validity**: We have the records, but they're not valid, i.e., they don't conform to a defined schema, also known as a defined set of rules for data.\n",
    "3. **Accuracy**: Inaccurate data is wrong data that is valid. It adheres to the defined schema, but it is still incorrect.\n",
    "4. **Consistency**: Inconsistent data is both valid and accurate, but there are multiple correct ways of referring to the same thing.\n",
    "\n",
    "#### <a id='toc1_4_1_2_'></a>[Tidiness:](#toc0_)\n",
    "- Tidy data has 3 qualities:\n",
    "    - Each variable forms a column.\n",
    "    - Each observation forms a row.\n",
    "    - Each type of observational unit forms a table.\n",
    "\n",
    "## <a id='toc1_5_'></a>[Order for Addressing Problems:](#toc0_)\n",
    "\n",
    " 1. **Completeness issues** or **Fix Missing Data**: It's important to do this upfront so that subsequent data cleaning will not have to be repeated.\n",
    " 2. **Tidy the Tables**: Tidy datasets with data quality issues are almost always easier to clean than untidy datasets with the same issues.\n",
    " 3. **Quality Control**: Address the remaining validity, accuracy, and consistency issues."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[**Demo**](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_1_'></a>[**Gathering**](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_1_1_'></a>[Setup](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_1_2_'></a>[Load](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in csv file on disk\n",
    "twitter_df = pd.read_csv('Data/twitter-archive-enhanced (1).csv')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_2_'></a>[**Assess**](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_2_1_'></a>[Programmatic Assessment](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_2_2_'></a>[Visual Assessment](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_2_3_'></a>[List of Issues to Resolve](#toc0_)\n",
    "\n",
    "List of Issues to Fix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_2_3_1_'></a>[Quality issues](#toc0_)\n",
    "\n",
    "1. api_df has 30 missing tweet entries compared with the twitter_df. - Completeness\n",
    "\n",
    "2. image_df has 281 less data entries as compared with twitter_df and potentially has multiple images for some entries. - Completeness\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### <a id='toc2_2_3_2_'></a>[Tidiness issues](#toc0_)\n",
    "   \n",
    "1.   Numerator and Denominator are in two separate columns although they are one piece of information. - Columns  \n",
    "     -    Combine these two columns into a new singular column. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_3_'></a>[**Clean**](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_3_1_'></a>[Issue #1:](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_3_1_1_'></a>[Define:](#toc0_)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The first issues I wanted to address were all the Completeness issues. However, they would all be much easier to accomplish if I merged the 3 dfs together. This would accomplish three of my issues in one swoop. Here is my breakdown of each issue.\n",
    "\n",
    "**Quality**:\n",
    "1. api_df has 30 missing tweet entries compared with the twitter_df. - Completeness  \n",
    "   - Check to see if there is some commonality with the missing tweets. Otherwise, consider deleting incomplete data from twitter_df. \n",
    "\n",
    "2. image_df has 281 less data entries as compared with twitter_df and potentially has multiple images for some entries. - Completeness\n",
    "   - Check to see if there is some commonality with the missing tweets. Otherwise, consider deleting incomplete data from twitter_df. \n",
    "\n",
    "**Tidiness**:   \n",
    "\n",
    "2. Combine the three dataframes into one master dataframe on tweet_id. - Tables   \n",
    "   - Use pd.merge to merge all three dfs on tweet_id\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_3_1_2_'></a>[Code](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.merge(clean_twitter_df, clean_api_df,\\\n",
    "                                how='outer', on='tweet_id', sort=True, copy=True)\n",
    "\n",
    "master_df = pd.merge(master_df, clean_image_df,\\\n",
    "                                how='outer', on='tweet_id', sort=True, copy=True)\n",
    "\n",
    "print(master_df.columns)\n",
    "\n",
    "master_df.info()\n",
    "master_df.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_3_1_3_'></a>[Test](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.info()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_3_2_'></a>[Issue #2:....](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_3_1_1_'></a>[Define:](#toc0_)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_3_1_2_'></a>[Code](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_3_1_3_'></a>[Test](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
